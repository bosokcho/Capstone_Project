# Checkpoint 7

** Madeline Abbott, Aidan Teppema, Daisy Cho **

\


```{r include=FALSE}
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(zoo)
library(lubridate)
library(ggmap)
library(reshape2)
library(MASS)
library(viridis)
#library(shiny)
library(rjags)
library(MacBayes)
```

Loading the data...
```{r include=FALSE}
# Loading the Data
hurricane_data <- read_csv("Historical_Tropical_Storm_Tracks.csv")
hurricane_data<-na.omit(hurricane_data)
hurricane_data<-subset(hurricane_data, select=-c(BTID, AD_TIME))

# Recent Hurricanes--select only hurricanes in 1950 and after
recent_hurricanes <- hurricane_data[hurricane_data$YEAR >= 1950, ] 
recent_hurricanes <- recent_hurricanes[!(recent_hurricanes$NAME=="NOTNAMED"),]
#Format Coordinates
dat<-as.character(recent_hurricanes$LAT)
new<-substr(dat,1,nchar(dat))
lat<-as.numeric(new)
dat<-as.character(recent_hurricanes$LONG)
new<-substr(dat,1,nchar(dat))
long<-as.numeric(new)
long<- -abs(long)
coord<-as.data.frame(long)
#Add year and name
year<-as.character(recent_hurricanes$YEAR)
name<-as.character(recent_hurricanes$NAME)
hurricane_locations<-cbind(year, name, coord, lat)

# Hurricane Frequency
# table of hurricanes per year
hurricanes_per_year <- recent_hurricanes %>%
  group_by(YEAR) %>%
  summarise(TOTAL_H = n_distinct(NAME))
hurricanes_per_basin <- recent_hurricanes %>%
  group_by(BASIN) %>%
  summarise(TOTAL_H = n_distinct(NAME, DAY))

# Temperature Data
temp_data <- read.csv("ZonAnn.csv")
temp_data[!complete.cases(temp_data),]
temp_data<-na.omit(temp_data)
temp_data<-temp_data[,-(5:15),drop=FALSE]
temp_recent <- temp_data %>%
  filter(Year > 1949)
# select only northern hemisphere temp data
tempN <- subset(temp_recent, select = c(Year, NHem))
# rename the columns
colnames(tempN) <- c("YEAR", "temp")
# join temperature to hurricanes per year table
hurricanes_per_year2 <- merge(x = hurricanes_per_year, y = tempN, by = "YEAR", all.x = TRUE)

# CO2 Data
CO2 <- read_csv("CO2.csv")
# Alter CO2 to remove unnecessary variable trend
CO2 <- subset(CO2, select = -trend)
# get average by year
CO2_yr <- CO2 %>%
  group_by(year) %>%
  summarise(avg_CO2 = mean(average))
# rename columns
colnames(CO2_yr) <- c("YEAR", "avg_CO2")
# join with hurricane per year table
hurricanes_per_year3 <- merge(x = hurricanes_per_year2, y = CO2_yr, by = "YEAR", all.x = TRUE)
# FIX THIS (bc only 1980 onward available)

# NAO Index Data
NAO_index1 <- read_csv("NAO_index_monthly.csv", 
    col_types = cols(Apr = col_number(), 
        Aug = col_number(), Dec = col_number(), 
        Feb = col_number(), Jan = col_number(), 
        Jul = col_number(), Jun = col_number(), 
        Mar = col_number(), May = col_number(), 
        Nov = col_number(), Oct = col_number(), 
        Sep = col_number()))
NAO_index2 <- NAO_index1[, -c(14)]
NAO_index3 <- NAO_index2 %>%
  rename(year = X1) %>%
  mutate(Jul = replace(Jul, Jul < -50| Jul > 50, "")) %>%
  mutate(Aug = replace(Aug, Aug < -50| Aug > 50, "")) %>%
  mutate(Sep = replace(Sep, Sep < -50| Sep > 50, "")) %>%
  mutate(Oct = replace(Oct, Oct < -50| Oct > 50, "")) %>%
  mutate(Nov = replace(Nov, Nov < -50| Nov > 50, "")) %>%
  mutate(Dec = replace(Dec, Dec < -50| Dec > 50, ""))
NAO_index <- NAO_index3[-nrow(NAO_index3),] 
# remove 2017 (data for year is incomplete)
NAO_index <- head(NAO_index, -1) 
# reshape table
NAO_index <- melt(NAO_index, id=c("year"))
colnames(NAO_index)[2] <- "month"
colnames(NAO_index)[3] <- "index"
NAO_index$year <- as.factor(NAO_index$year)
NAO_index$index <- as.numeric(NAO_index$index)
# group by year
NAO_yr <- NAO_index %>%
  group_by(year) %>%
  summarise(avg_NAO = mean(index))
# rename columns
colnames(NAO_yr) <- c("YEAR", "avg_NAO")
# join with hurricane data
hurricanes_per_year4 <- merge(x = hurricanes_per_year3, y = NAO_yr, by = "YEAR", all.x = TRUE)

# Remove all rows with missing data
hurricanes_per_year_clean<-na.omit(hurricanes_per_year4)

head(hurricanes_per_year_clean)
```


# Progress Made:

Possible things we could do:

* include only Atlantic ocean hurricanes [ ]

* check for colinearity between explanatory variables [DONE]

* include year as a predictor in model [ ]

* model for hurricane severity (see Alicia's email) [ ]

* predict occurance of next (severe landfall?) hurricane using exponential distribution [ ]

\
\


# Group Member Roles:

* Madeline--
* Daisy--
* Aidan--

\
\


# Modeling:


\


## Question 1.

Can we model the change in frequency of hurricanes based on trends in hurricane windspeed and category, temperature, CO2, and NAO index?


First, we check for colinarity between the explanatory variables of temperature, CO2, and NAO index.
```{r}
cor(x = as.matrix(hurricanes_per_year_clean$temp), y = as.matrix(hurricanes_per_year_clean$avg_CO2))

cor(x = as.matrix(hurricanes_per_year_clean$avg_NAO), y = as.matrix(hurricanes_per_year_clean$temp))

cor(x = as.matrix(hurricanes_per_year_clean$avg_NAO), y = as.matrix(hurricanes_per_year_clean$avg_CO2))
```

Based on the correlation coefficient between temperature and average CO2 concentration, we remove temperature to reduce collinarity.

Build a new poisson regression model for predicting using only NAO index and CO2 concentration.

Let:

$Y_{t} =$ total hurricanes in year $t$

$X_{1t} =$ yearly CO2 concentration in year $t$

$X_{2t} =$ NAO index in year $t$

We propose the following model:

$$Y_t | \beta_{0}, \beta_{1}, \beta_{2} \sim Pois(\lambda_i)$$

$$log(\lambda_i) = \beta_0 + \beta_{1}X_{1t} + \beta_{2}X_{2t}$$

$$\beta_0 \sim N(0, 1e6)$$

$$\beta_{1} \sim N(0, 1e6)$$

$$\beta_{2} \sim N(0, 1e6)$$



Simulating the model using rjags:
```{r echo=FALSE}
head(hurricanes_per_year_clean)

hur_mod <- " model {
  for (i in 1:length(TOTAL_H)) {
      TOTAL_H[i] ~ dpois(lam[i])
      log(lam[i]) = beta0 + beta1*X1[i] + beta2*X2[i]
  }

  beta0 ~ dnorm(0.0, 1.0/1e6)
  beta1 ~ dnorm(0.0, 1.0/1e4)
  beta2 ~ dnorm(0.0, 1.0/1e4)
} "

# set up an algorithm to simulate the posterior by combining the model and data (x)
# set the random number seed

data_jags = as.list(hurricanes_per_year_clean[,2:5])
str(data_jags)

#freq_jags <- jags.model(textConnection(hur_mod),data=list(TOTAL_H = hurricanes_per_year_clean$TOTAL_H, X1 = hurricanes_per_year_clean$temp, X2 = hurricanes_per_year_clean$avg_CO2,X3 = hurricanes_per_year_clean$avg_NAO), inits=list(.RNG.name="base::Wichmann-Hill", .RNG.seed=2000))

# manually initialize parameters
freq_jags <- jags.model(textConnection(hur_mod),data=list(TOTAL_H = hurricanes_per_year_clean$TOTAL_H, X1 = hurricanes_per_year_clean$avg_CO2,X2 = hurricanes_per_year_clean$avg_NAO), inits=list(beta0=5,beta1=0, beta2=0))

# simulate a sample from the posterior
# note that we specify both mu and tau variables
freq_sim <- coda.samples(freq_jags, variable.names = c("beta0", "beta1", "beta2"), n.iter=5000)

# store the samples in a data frame:
freq_sample <- data.frame(step = 1:5000, freq_sim[[1]])
head(freq_sample, 10)


# make a dataframe of parameter values every other step to make plotting faster
Nth.delete<-function(dataframe, n)dataframe[-(seq(n,to=nrow(dataframe),by=n)),]
freq_sample_small <- Nth.delete(freq_sample, 2)
```

Looking at convergence
```{r echo=FALSE}
library(MacBayes)
running_mean_plot(x=freq_sample_small$beta0, se=TRUE)
running_mean_plot(x=freq_sample_small$beta1, se=TRUE)
running_mean_plot(x=freq_sample_small$beta2, se=TRUE)
```

Based on the running mean plots, parameters look like they have converged.  Parameter mean values and 95% credible intervals are as follows:
```{r echo=FALSE}
quantile(freq_sample$beta0, c(0.05, 0.975)) 
quantile(freq_sample$beta1, c(0.05, 0.975))
quantile(freq_sample$beta2, c(0.05, 0.975))

mean(freq_sample$beta0)
mean(freq_sample$beta1)
mean(freq_sample$beta2)
```

Beta0 has a mean of 2.327235 and a 95% CI of (0.7864641, 4.1668185).

Beta1 has a mean of 0.002818374 and a 95% CI of (-0.001344940, 0.007860139).

Beta2 has a mean of 0.001306308 and a 95% CI of (-0.1105324, 0.1350339).

\

From these results, we conclude that average annual CO2 concentration and NAO index are not useful predictors of hurricane frequency.


## Hurricanes by Zones

Divide northern hemisphere into four zones.  Get temperature from 1950 for each of these zones.
```{r}
temp_data <- read_csv("ZonAnn.csv")
temp_data<-na.omit(temp_data) %>%
  filter(1950 <= Year) %>%
  filter(Year <= 2008)
my_temp <- subset(temp_data, select = c("Year", "64N-90N", "44N-64N", "24N-44N", "EQU-24N"))
colnames(my_temp) <- c("Year", "N64to90", "N44to64", "N24to44", "EQUtoN24")
my_temp <- melt(my_temp, id=c("Year"))
colnames(my_temp) <- c("year", "zone", "temp")
head(my_temp)
```

Now divide hurricane observations into these same four zones.
(Currently using all hurricane locations to see if temperature affects where hurricanes occur, not just where they are the most severe.  Could also switch to use just the location at which each hurricane is most severe.)
```{r}
head(hurricane_locations)

hurricanes_zones <- hurricane_locations %>% 
  mutate(zone=cut(lat, breaks=c(0, 24, 44, 64, 90), labels=c("N64to90", "N44to64", "N24to44", "EQUtoN24"))) %>%
  group_by(year, zone)  %>%
  summarise(total = n())

head(hurricanes_zones, 40)
```

Combine the hurricane and temperature data frames together
```{r}
hurricanes_per_zone <- merge(my_temp, hurricanes_zones, by = c("year", "zone"), all.x = TRUE, all.y = TRUE)
hurricanes_per_zone[is.na(hurricanes_per_zone)] <- 0
head(hurricanes_per_zone)
```


Poisson regression--just with temperature
```{r echo=FALSE}
hur_mod2 <- " model {
  for (i in 1:length(total)) {
      total[i] ~ dpois(lam[i])
      log(lam[i]) = beta0 + beta1*X1[i]
  }

  beta0 ~ dnorm(0.0, 1.0/1e6)
  beta1 ~ dnorm(0.0, 1.0/1e4)
} "

# set up an algorithm to simulate the posterior by combining the model and data (x)
# set the random number seed
freq_jags2 <- jags.model(textConnection(hur_mod2),data=list(total = hurricanes_per_zone$total, X1 = hurricanes_per_zone$temp), inits=list(.RNG.name="base::Wichmann-Hill", .RNG.seed=2000))

# simulate a sample from the posterior
freq_sim2 <- coda.samples(freq_jags2, variable.names = c("beta0", "beta1"), n.iter=5000)

# store the samples in a data frame:
freq_sample2 <- data.frame(step = 1:5000, freq_sim2[[1]])
head(freq_sample2, 10)
```

Look at the estimated parameters--have they coverged?
```{r echo=FALSE}
running_mean_plot(x=freq_sample2$beta0, se=TRUE)
running_mean_plot(x=freq_sample2$beta1, se=TRUE)
```

Based on the running mean plots, parameters look like they have converged.  Parameter mean values and 95% credible intervals are as follows:



```{r}
# Hurricane data only looking at Date and name
hurricane_time<-subset(recent_hurricanes, select = c(NAME,YEAR,MONTH,DAY))

#Group data by year and name and subtracting starting time from end time for each hurricane (duration)
foo <- hurricane_time %>%
  group_by(YEAR, NAME) %>%
  mutate(date = as.Date(paste(YEAR, MONTH, DAY, sep='-')), "%Y-%m-%d") %>%
  summarise(duration = max(date) - min(date))

#removed outlier
foo<-foo[!(foo$YEAR==1954 & foo$NAME=="ALICE"),]

# Averaging duration per year
foo<-group_by(foo, YEAR)%>%
  summarise(mean(duration))
# Name second column of data as Average_Duration
colnames(foo)[2] <- "duration"
colnames(foo)[1]<-"year"
#create durations with temperature data, CO2 data, NAOI data and frequency data
durations <- merge(foo, hurricanes_per_zone, by = c("year"), all.x = TRUE, all.y = TRUE)
```


```{r fig.height=6}
library(rjags)

#specify the model
duration_model <- "model{
    #Data
    for(i in 1:length(y)) {
        y[i] ~ dnorm(beta0 + beta1*X1[i] + beta2[X2[i]],tau)
    }

    #Priors
    beta0 ~ dnorm(0.0, 1.0/1e4)
    beta1 ~ dnorm(0.0, 1.0/1e4)
    beta2[1] <- 0
    for (i in 2:4) {
      beta2[i] ~ dnorm(0.0, 1.0/1e4)
  }
    tau ~ dgamma(.001, .001)
}"



duration_jags <- jags.model(textConnection(duration_model), data=list(y = durations$duration, X1 = durations$temp, X2 = durations$zone), inits=list(.RNG.name="base::Wichmann-Hill", .RNG.seed=1989))



duration_sim <- coda.samples(duration_jags, variable.names=c("beta0","beta1", "beta2","tau"), n.iter=10000)


   
duration_samples <- data.frame(step=1:10000, duration_sim[[1]])
head(duration_samples)
plot(duration_sim)
```

```{r}
running_mean_plot(x=freq_sample3$beta0, se=TRUE)
running_mean_plot(x=freq_sample3$beta1, se=TRUE)

running_mean_plot(x=freq_sample3$beta2.2., se=TRUE)
running_mean_plot(x=freq_sample3$beta2.3., se=TRUE)
running_mean_plot(x=freq_sample3$beta2.4., se=TRUE)
```


```{r}
quantile(freq_sample3$beta0, c(0.05, 0.975)) 
quantile(freq_sample3$beta1, c(0.05, 0.975))
quantile(freq_sample3$beta2.2., c(0.05, 0.975))
quantile(freq_sample3$beta2.3., c(0.05, 0.975))
quantile(freq_sample3$beta2.4., c(0.05, 0.975))

mean(freq_sample3$beta0)
mean(freq_sample3$beta1)
mean(freq_sample3$beta2.2.)
mean(freq_sample3$beta2.3.)
mean(freq_sample3$beta2.4.)
```